The facial emotion classification model utilizes a Convolutional Neural Network (CNN) architecture designed to analyze 48x48 pixel grayscale images of faces. The model consists of multiple layers, including Conv2D layers for feature extraction, MaxPooling2D layers for down-sampling, and Dropout layers to prevent overfitting. The final output layer employs a softmax activation function to categorize the emotions into seven distinct classes: Angry (0), Disgust (1), Fear (2), Happy (3), Sad (4), Surprise (5), and Neutral (6). The dataset used for training comprises 28,709 examples, with an additional 3,589 examples in the public test set. These images have been automatically registered to ensure that the faces are centered and occupy a consistent amount of space, enabling the model to effectively classify emotions from real-time webcam input.
