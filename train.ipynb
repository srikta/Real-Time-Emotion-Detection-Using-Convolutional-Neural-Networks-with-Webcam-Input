{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required models\n",
    "from tensorflow.keras import layers, Sequential, models\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize image data generator with generator wuth rescaling\n",
    "train_data_gen = ImageDataGenerator(rescale=1./255)\n",
    "validation_data_gen = ImageDataGenerator(rescale=1./255)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28709 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "#preprocess all test images\n",
    "train_generator = train_data_gen.flow_from_directory(\n",
    "    'data/train',\n",
    "    target_size=(48,48),\n",
    "    batch_size=64,\n",
    "    color_mode=\"grayscale\",\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7178 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_generator = train_data_gen.flow_from_directory(\n",
    "    'data/test',\n",
    "    target_size=(48,48),\n",
    "    batch_size=64,\n",
    "    color_mode=\"grayscale\",\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\souri\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "#create moedel architecture\n",
    "\n",
    "emotion_model = models.Sequential ([\n",
    "    layers.Conv2D(filters=32, kernel_size=(3,3), activation='relu', input_shape=(48,48,1)),\n",
    "    layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu'),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    layers.Dropout(0.25),\n",
    "\n",
    "    layers.Conv2D(filters=128, kernel_size=(3,3), activation='relu'),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    layers.Conv2D(filters=128, kernel_size=(3,3), activation='relu'),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    layers.Dropout(0.25), \n",
    "\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(1024, activation='relu'),\n",
    "    layers.Dropout(0.25),\n",
    "    layers.Dense(7, activation='softmax')\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_model.compile(\n",
    "    optimizer='adam' ,\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\souri\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 111ms/step - accuracy: 0.2758 - loss: 1.7675 - val_accuracy: 0.4411 - val_loss: 1.4523\n",
      "Epoch 2/100\n",
      "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80us/step - accuracy: 0.4688 - loss: 1.5547 - val_accuracy: 0.5000 - val_loss: 1.5622\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\souri\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py:158: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 115ms/step - accuracy: 0.4445 - loss: 1.4269 - val_accuracy: 0.5142 - val_loss: 1.2761\n",
      "Epoch 4/100\n",
      "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44us/step - accuracy: 0.5000 - loss: 1.3775 - val_accuracy: 0.4000 - val_loss: 1.3430\n",
      "Epoch 5/100\n",
      "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 118ms/step - accuracy: 0.5199 - loss: 1.2570 - val_accuracy: 0.5451 - val_loss: 1.1767\n",
      "Epoch 6/100\n",
      "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74us/step - accuracy: 0.5000 - loss: 1.0228 - val_accuracy: 0.9000 - val_loss: 0.8314\n",
      "Epoch 7/100\n",
      "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 124ms/step - accuracy: 0.5593 - loss: 1.1716 - val_accuracy: 0.5660 - val_loss: 1.1410\n",
      "Epoch 8/100\n",
      "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56us/step - accuracy: 0.5938 - loss: 1.0849 - val_accuracy: 0.5000 - val_loss: 1.3224\n",
      "Epoch 9/100\n",
      "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 124ms/step - accuracy: 0.5835 - loss: 1.1013 - val_accuracy: 0.5738 - val_loss: 1.1212\n",
      "Epoch 10/100\n",
      "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48us/step - accuracy: 0.5781 - loss: 1.3224 - val_accuracy: 0.5000 - val_loss: 1.0278\n",
      "Epoch 11/100\n",
      "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m306s\u001b[0m 685ms/step - accuracy: 0.5954 - loss: 1.0646 - val_accuracy: 0.5749 - val_loss: 1.1053\n",
      "Epoch 12/100\n",
      "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122us/step - accuracy: 0.5625 - loss: 1.3079 - val_accuracy: 0.5000 - val_loss: 1.4571\n",
      "Epoch 13/100\n",
      "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 117ms/step - accuracy: 0.6142 - loss: 1.0097 - val_accuracy: 0.5806 - val_loss: 1.1043\n",
      "Epoch 14/100\n",
      "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78us/step - accuracy: 0.6250 - loss: 1.0938 - val_accuracy: 0.3000 - val_loss: 1.5375\n",
      "Epoch 15/100\n",
      "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 115ms/step - accuracy: 0.6377 - loss: 0.9621 - val_accuracy: 0.5958 - val_loss: 1.0691\n",
      "Epoch 16/100\n",
      "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49us/step - accuracy: 0.5938 - loss: 1.0672 - val_accuracy: 0.4000 - val_loss: 1.3814\n",
      "Epoch 17/100\n",
      "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 115ms/step - accuracy: 0.6620 - loss: 0.9057 - val_accuracy: 0.5975 - val_loss: 1.0789\n",
      "Epoch 18/100\n",
      "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42us/step - accuracy: 0.6719 - loss: 0.8891 - val_accuracy: 0.5000 - val_loss: 1.0374\n",
      "Epoch 19/100\n",
      "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 115ms/step - accuracy: 0.6814 - loss: 0.8485 - val_accuracy: 0.6010 - val_loss: 1.0649\n",
      "Epoch 20/100\n",
      "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44us/step - accuracy: 0.7344 - loss: 0.7716 - val_accuracy: 0.6000 - val_loss: 1.2088\n",
      "Epoch 21/100\n",
      "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 113ms/step - accuracy: 0.7050 - loss: 0.8027 - val_accuracy: 0.6099 - val_loss: 1.0792\n",
      "Epoch 22/100\n",
      "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76us/step - accuracy: 0.6562 - loss: 0.8893 - val_accuracy: 0.8000 - val_loss: 0.4165\n",
      "Epoch 23/100\n",
      "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 114ms/step - accuracy: 0.7141 - loss: 0.7713 - val_accuracy: 0.6044 - val_loss: 1.0772\n",
      "Epoch 24/100\n",
      "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41us/step - accuracy: 0.7188 - loss: 0.6564 - val_accuracy: 0.4000 - val_loss: 1.6355\n",
      "Epoch 25/100\n",
      "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 117ms/step - accuracy: 0.7328 - loss: 0.7223 - val_accuracy: 0.6024 - val_loss: 1.1006\n",
      "Epoch 26/100\n",
      "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47us/step - accuracy: 0.7188 - loss: 0.7158 - val_accuracy: 0.8000 - val_loss: 0.5735\n",
      "Epoch 27/100\n",
      "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 116ms/step - accuracy: 0.7501 - loss: 0.6716 - val_accuracy: 0.6094 - val_loss: 1.1063\n",
      "Epoch 28/100\n",
      "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75us/step - accuracy: 0.7344 - loss: 0.7040 - val_accuracy: 0.4000 - val_loss: 1.1116\n",
      "Epoch 29/100\n",
      "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 116ms/step - accuracy: 0.7545 - loss: 0.6469 - val_accuracy: 0.6063 - val_loss: 1.1257\n",
      "Epoch 30/100\n",
      "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23us/step - accuracy: 0.7031 - loss: 0.7212 - val_accuracy: 0.5000 - val_loss: 1.4231\n",
      "Epoch 31/100\n",
      "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 112ms/step - accuracy: 0.7736 - loss: 0.6135 - val_accuracy: 0.6140 - val_loss: 1.1331\n",
      "Epoch 32/100\n",
      "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45us/step - accuracy: 0.7344 - loss: 0.6271 - val_accuracy: 0.5000 - val_loss: 1.4870\n",
      "Epoch 33/100\n",
      "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 114ms/step - accuracy: 0.7879 - loss: 0.5820 - val_accuracy: 0.6046 - val_loss: 1.1523\n",
      "Epoch 34/100\n",
      "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72us/step - accuracy: 0.8438 - loss: 0.4769 - val_accuracy: 0.5000 - val_loss: 2.5305\n",
      "Epoch 35/100\n",
      "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 116ms/step - accuracy: 0.7924 - loss: 0.5566 - val_accuracy: 0.6034 - val_loss: 1.1810\n",
      "Epoch 36/100\n",
      "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52us/step - accuracy: 0.6406 - loss: 0.8249 - val_accuracy: 0.5000 - val_loss: 0.7567\n",
      "Epoch 37/100\n",
      "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 115ms/step - accuracy: 0.8090 - loss: 0.5270 - val_accuracy: 0.6126 - val_loss: 1.1898\n",
      "Epoch 38/100\n",
      "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72us/step - accuracy: 0.7344 - loss: 0.7616 - val_accuracy: 0.8000 - val_loss: 1.5004\n",
      "Epoch 39/100\n",
      "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 113ms/step - accuracy: 0.8186 - loss: 0.5035 - val_accuracy: 0.5979 - val_loss: 1.2037\n",
      "Epoch 40/100\n",
      "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30us/step - accuracy: 0.7812 - loss: 0.5723 - val_accuracy: 0.6000 - val_loss: 0.9856\n",
      "Epoch 41/100\n",
      "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 111ms/step - accuracy: 0.8201 - loss: 0.4848 - val_accuracy: 0.6098 - val_loss: 1.2046\n",
      "Epoch 42/100\n",
      "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67us/step - accuracy: 0.8594 - loss: 0.4130 - val_accuracy: 0.6000 - val_loss: 1.9489\n",
      "Epoch 43/100\n",
      "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 111ms/step - accuracy: 0.8282 - loss: 0.4673 - val_accuracy: 0.6144 - val_loss: 1.2422\n",
      "Epoch 44/100\n",
      "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38us/step - accuracy: 0.8906 - loss: 0.3889 - val_accuracy: 0.8000 - val_loss: 0.5491\n",
      "Epoch 45/100\n",
      "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 110ms/step - accuracy: 0.8361 - loss: 0.4544 - val_accuracy: 0.6119 - val_loss: 1.2395\n",
      "Epoch 46/100\n",
      "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27us/step - accuracy: 0.8750 - loss: 0.4050 - val_accuracy: 0.5000 - val_loss: 0.9440\n",
      "Epoch 47/100\n",
      "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 170ms/step - accuracy: 0.8406 - loss: 0.4316 - val_accuracy: 0.6138 - val_loss: 1.2605\n",
      "Epoch 48/100\n",
      "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17us/step - accuracy: 0.8750 - loss: 0.4278 - val_accuracy: 0.7000 - val_loss: 0.7811\n",
      "Epoch 49/100\n",
      "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 111ms/step - accuracy: 0.8501 - loss: 0.4145 - val_accuracy: 0.6098 - val_loss: 1.2424\n",
      "Epoch 50/100\n",
      "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37us/step - accuracy: 0.8281 - loss: 0.3906 - val_accuracy: 0.9000 - val_loss: 0.5370\n",
      "Epoch 51/100\n",
      "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 115ms/step - accuracy: 0.8563 - loss: 0.4048 - val_accuracy: 0.6124 - val_loss: 1.2906\n",
      "Epoch 52/100\n",
      "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18us/step - accuracy: 0.8281 - loss: 0.5093 - val_accuracy: 0.8000 - val_loss: 0.6109\n",
      "Epoch 53/100\n",
      "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 113ms/step - accuracy: 0.8646 - loss: 0.3787 - val_accuracy: 0.6094 - val_loss: 1.2999\n",
      "Epoch 54/100\n",
      "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59us/step - accuracy: 0.8594 - loss: 0.3652 - val_accuracy: 0.6000 - val_loss: 2.6011\n",
      "Epoch 55/100\n",
      "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 115ms/step - accuracy: 0.8614 - loss: 0.3948 - val_accuracy: 0.6064 - val_loss: 1.2723\n",
      "Epoch 56/100\n",
      "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34us/step - accuracy: 0.8438 - loss: 0.5295 - val_accuracy: 0.7000 - val_loss: 1.0775\n",
      "Epoch 57/100\n",
      "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 112ms/step - accuracy: 0.8610 - loss: 0.3829 - val_accuracy: 0.5988 - val_loss: 1.3396\n",
      "Epoch 58/100\n",
      "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74us/step - accuracy: 0.8594 - loss: 0.4149 - val_accuracy: 0.6000 - val_loss: 1.0832\n",
      "Epoch 59/100\n",
      "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 237ms/step - accuracy: 0.8688 - loss: 0.3652 - val_accuracy: 0.6123 - val_loss: 1.3550\n",
      "Epoch 60/100\n",
      "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44us/step - accuracy: 0.8281 - loss: 0.4118 - val_accuracy: 0.6000 - val_loss: 1.8326\n",
      "Epoch 61/100\n",
      "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 110ms/step - accuracy: 0.8791 - loss: 0.3438 - val_accuracy: 0.6137 - val_loss: 1.3627\n",
      "Epoch 62/100\n",
      "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37us/step - accuracy: 0.8438 - loss: 0.4035 - val_accuracy: 0.5000 - val_loss: 1.2416\n",
      "Epoch 63/100\n",
      "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 113ms/step - accuracy: 0.8765 - loss: 0.3489 - val_accuracy: 0.6110 - val_loss: 1.3407\n",
      "Epoch 64/100\n",
      "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68us/step - accuracy: 0.8906 - loss: 0.3043 - val_accuracy: 0.7000 - val_loss: 1.0144\n",
      "Epoch 65/100\n",
      "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 114ms/step - accuracy: 0.8797 - loss: 0.3348 - val_accuracy: 0.6060 - val_loss: 1.3554\n",
      "Epoch 66/100\n",
      "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23us/step - accuracy: 0.8906 - loss: 0.3497 - val_accuracy: 0.8000 - val_loss: 0.5487\n",
      "Epoch 67/100\n",
      "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 113ms/step - accuracy: 0.8790 - loss: 0.3380 - val_accuracy: 0.6143 - val_loss: 1.3548\n",
      "Epoch 68/100\n",
      "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46us/step - accuracy: 0.8438 - loss: 0.4416 - val_accuracy: 0.7000 - val_loss: 1.6988\n",
      "Epoch 69/100\n",
      "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 113ms/step - accuracy: 0.8830 - loss: 0.3255 - val_accuracy: 0.6154 - val_loss: 1.3836\n",
      "Epoch 70/100\n",
      "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33us/step - accuracy: 0.9219 - loss: 0.3154 - val_accuracy: 0.7000 - val_loss: 0.9813\n",
      "Epoch 71/100\n",
      "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 283ms/step - accuracy: 0.8899 - loss: 0.3118 - val_accuracy: 0.6084 - val_loss: 1.3573\n",
      "Epoch 72/100\n",
      "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40us/step - accuracy: 0.8438 - loss: 0.3475 - val_accuracy: 0.6000 - val_loss: 1.0687\n",
      "Epoch 73/100\n",
      "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 114ms/step - accuracy: 0.8888 - loss: 0.3097 - val_accuracy: 0.6099 - val_loss: 1.3443\n",
      "Epoch 74/100\n",
      "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47us/step - accuracy: 0.9219 - loss: 0.3491 - val_accuracy: 0.5000 - val_loss: 1.4024\n",
      "Epoch 75/100\n",
      "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 115ms/step - accuracy: 0.8925 - loss: 0.3035 - val_accuracy: 0.6161 - val_loss: 1.3547\n",
      "Epoch 76/100\n",
      "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34us/step - accuracy: 0.8906 - loss: 0.2817 - val_accuracy: 0.6000 - val_loss: 3.2633\n",
      "Epoch 77/100\n",
      "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 123ms/step - accuracy: 0.8899 - loss: 0.3065 - val_accuracy: 0.6123 - val_loss: 1.4102\n",
      "Epoch 78/100\n",
      "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45us/step - accuracy: 0.9459 - loss: 0.2148 - val_accuracy: 0.4000 - val_loss: 1.5023\n",
      "Epoch 79/100\n",
      "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 116ms/step - accuracy: 0.8897 - loss: 0.3140 - val_accuracy: 0.6055 - val_loss: 1.4461\n",
      "Epoch 80/100\n",
      "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30us/step - accuracy: 0.8750 - loss: 0.3039 - val_accuracy: 0.4000 - val_loss: 1.4801\n",
      "Epoch 81/100\n",
      "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 115ms/step - accuracy: 0.8935 - loss: 0.3079 - val_accuracy: 0.6085 - val_loss: 1.4001\n",
      "Epoch 82/100\n",
      "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31us/step - accuracy: 0.8906 - loss: 0.2558 - val_accuracy: 0.3000 - val_loss: 3.3130\n",
      "Epoch 83/100\n",
      "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 113ms/step - accuracy: 0.8967 - loss: 0.2989 - val_accuracy: 0.6115 - val_loss: 1.3997\n",
      "Epoch 84/100\n",
      "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49us/step - accuracy: 0.8594 - loss: 0.3170 - val_accuracy: 0.4000 - val_loss: 1.0443\n",
      "Epoch 85/100\n",
      "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 118ms/step - accuracy: 0.9001 - loss: 0.2864 - val_accuracy: 0.6138 - val_loss: 1.4019\n",
      "Epoch 86/100\n",
      "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47us/step - accuracy: 0.8906 - loss: 0.2551 - val_accuracy: 0.8000 - val_loss: 0.5208\n",
      "Epoch 87/100\n",
      "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 128ms/step - accuracy: 0.9037 - loss: 0.2845 - val_accuracy: 0.6122 - val_loss: 1.3872\n",
      "Epoch 88/100\n",
      "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52us/step - accuracy: 0.8594 - loss: 0.4168 - val_accuracy: 0.8000 - val_loss: 0.9955\n",
      "Epoch 89/100\n",
      "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 130ms/step - accuracy: 0.9015 - loss: 0.2836 - val_accuracy: 0.6067 - val_loss: 1.4558\n",
      "Epoch 90/100\n",
      "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26us/step - accuracy: 0.8750 - loss: 0.4349 - val_accuracy: 0.5000 - val_loss: 1.3264\n",
      "Epoch 91/100\n",
      "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 115ms/step - accuracy: 0.9015 - loss: 0.2783 - val_accuracy: 0.6145 - val_loss: 1.4838\n",
      "Epoch 92/100\n",
      "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31us/step - accuracy: 0.9688 - loss: 0.1173 - val_accuracy: 0.6000 - val_loss: 2.2482\n",
      "Epoch 93/100\n",
      "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 114ms/step - accuracy: 0.9014 - loss: 0.2807 - val_accuracy: 0.6090 - val_loss: 1.5239\n",
      "Epoch 94/100\n",
      "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45us/step - accuracy: 0.8906 - loss: 0.3218 - val_accuracy: 0.5000 - val_loss: 2.3107\n",
      "Epoch 95/100\n",
      "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 114ms/step - accuracy: 0.9034 - loss: 0.2825 - val_accuracy: 0.6080 - val_loss: 1.4217\n",
      "Epoch 96/100\n",
      "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55us/step - accuracy: 0.8594 - loss: 0.3771 - val_accuracy: 0.5000 - val_loss: 2.2978\n",
      "Epoch 97/100\n",
      "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 114ms/step - accuracy: 0.9131 - loss: 0.2493 - val_accuracy: 0.6078 - val_loss: 1.4250\n",
      "Epoch 98/100\n",
      "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46us/step - accuracy: 0.9375 - loss: 0.2485 - val_accuracy: 0.6000 - val_loss: 0.8621\n",
      "Epoch 99/100\n",
      "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 113ms/step - accuracy: 0.9089 - loss: 0.2677 - val_accuracy: 0.6087 - val_loss: 1.4799\n",
      "Epoch 100/100\n",
      "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38us/step - accuracy: 0.9375 - loss: 0.2449 - val_accuracy: 0.4000 - val_loss: 1.3397\n"
     ]
    }
   ],
   "source": [
    "emotion_model_info = emotion_model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=28709 // 64,  # Number of training batches\n",
    "    epochs=100,                     # Number of epochs to train\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=7178 // 64    # Number of validation batches\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model sttructure is json file\n",
    "model_json = emotion_model.to_json()\n",
    "with open(\"emotion_model.json\",\"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "#save trained model weight in .h5 file\n",
    "emotion_model.save_weights('emotion_model.weights.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
